{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sb\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import urllib\n",
    "#------------------\n",
    "sys.path.append(\"..\")\n",
    "from scripts.dataset import RandomTestDataset\n",
    "from scripts.models import MLP\n",
    "from scripts.resnet_family import resnet20_cifar\n",
    "from scripts.utils_cm import compute_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax probabilites vs model uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax gives you a notion of confidence for choosing a class over other classes known to the network. \n",
    "It does NOT provide you with the uncertainty of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the confidence of the model on unseen categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# image = image.resize((32, 32))\n",
    "transform = transforms.Compose([transforms.Resize((32, 32)), \n",
    "                                       transforms.ToTensor(), \n",
    "                                       transforms.Normalize(mean=[0.491, 0.482, 0.446], std=[0.247, 0.243, 0.261])])\n",
    "seen_classes = RandomTestDataset('./images/seen_cifar10', transform=transform)\n",
    "unseen_classes = RandomTestDataset('./images/unseen_cifar10', transform=transform)\n",
    "seen_dataloader = DataLoader(seen_classes, batch_size=1, shuffle=False)\n",
    "unseen_dataloader = DataLoader(unseen_classes, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels_cifar10 = ['airplanes', 'cars', 'birds', 'cats', 'deer', 'dogs', 'frogs', 'horses', 'ships', 'trucks']\n",
    "\n",
    "weights = torch.load('./weights/resnet20.th', map_location=torch.device('cpu'))['state_dict']\n",
    "model = resnet20_cifar(weights)\n",
    "model.eval()\n",
    "\n",
    "seen = []\n",
    "unseen = []\n",
    "\n",
    "for i_iter, batch in enumerate(seen_dataloader):\n",
    "    image, file_name = batch\n",
    "    output = model(image)\n",
    "    score, label = F.softmax(output, dim=1).max(1)\n",
    "    full_file_name = os.path.join('./images/seen_cifar10', file_name[0])\n",
    "    seen.append({'fname': full_file_name, 'prediction': labels_cifar10[label], 'score': np.round(score.item(), 3)})\n",
    "    \n",
    "for i_iter, batch in enumerate(unseen_dataloader):\n",
    "    image, file_name = batch\n",
    "    output = model(image)\n",
    "    score, label = F.softmax(output, dim=1).max(1)\n",
    "    full_file_name = os.path.join('./images/unseen_cifar10', file_name[0])\n",
    "    unseen.append({'fname': full_file_name, 'prediction': labels_cifar10[label], 'score': np.round(score.item(), 3)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 5, figsize=(16, 8))\n",
    "for i in range(len(seen)):\n",
    "    image = Image.open(seen[i]['fname'])\n",
    "    ax[0, i].imshow(image)\n",
    "    ax[0, i].set_title(f\"{seen[i]['prediction']}, {seen[i]['score']}\")\n",
    "    image = Image.open(unseen[i]['fname'])\n",
    "    ax[1, i].imshow(image)\n",
    "    ax[1, i].set_title(f\"{unseen[i]['prediction']}, {unseen[i]['score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of computing model uncertainty is to find out what the model does Not know. Then we should be more hesitant making decisions on thoses cases. As an example, when you train a machine learning model using either Maximum-Likelihood or Maximum-a-Posteriory algorithm, you end up with a point estimate for the model parameters $\\theta^*$. This leads to a fixed leanred model $h(\\theta^*)$, that always maps an input sample $x_0$ to $y_0 = h(x_0; \\theta^*)$. \n",
    "\n",
    "What if for a reason (for example staying on a saddle point in the parameters space) that mapping is not reliable and the model is very sensitive to small deviations of the input data? What might happen is that we might get $y_1 = h(x_1; \\theta^*)$ , where $y_1$ is far off from $y_0$, despite the fact that $\\|x_1 - x_0\\| < \\epsilon$.\n",
    "\n",
    "This is where embedding prior knowledge into the models (most commonly using Bayesian Learning/Inference) comes into play. The idea of Bayesian learning is to account for different possibilities for the model parameters rather than relying on some point estimates weights (which are offsprings of the MLE/MAP algorithms). These different possibilities are normally encoded using prior knowledge that is bound to the model parameters/weight. They are often defined as prior distributions over the parameters and used during model training, and then at the inference time, a set of parameters are sampled from their pre-definde distributions and used for making predictions.\n",
    "\n",
    "A natural extension of using Bayesian inference is thatthe models learned this way can be seamlessly used for ensemble predictions; I.e no extra training is required to produce multiple models, you just run the model with different prior samplings and get slightly different results, which is what proposed in this paper [YarinGalEtal-2016](http://proceedings.mlr.press/v48/gal16.pdf). \n",
    "\n",
    "Another advantage of Bayesian learning is that we don't need to worry that much about hyper-parameter optimisation and the state of the weights when training stops, because at the inference time we just integrate over the entire distribution of the parameters. This however is computationally interactable and we almost always would need to settle with approximate inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Processes, Bayesian Optimisation, and Bayesian NNs using DropOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good reads (and watch):\n",
    "[A Tutorial on Bayesian Optimization of Expensive Cost Functions](docs/BayesianOptimisation.pdf)\n",
    "\n",
    "[What My Deep Model Doesn't Know](http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html)\n",
    "\n",
    "[Leveraging uncertainty information from deep neural networks for disease detection](docs/BayesianDNN_nature_eye_disease.pdf)\n",
    "\n",
    "[Bayesian CNNs](https://arxiv.org/pdf/1506.02158.pdf)\n",
    "\n",
    "[Uncertainty Quantification and Deep Learning, Elise Jennings](https://www.youtube.com/watch?v=Puc_ujh5QZs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resemblance of Bayesian Neural networks and Gaussian Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single layer wide neural network with infinite number of neurons and probability distributions over the weights is mathematically equivalent to a Gaussian Process [Priors for Infinite Networks](https://www.cs.toronto.edu/~radford/ftp/pin.pdf), [Deep Neural Networks as Gaussian Processes](https://openreview.net/pdf?id=B1EA-M-0Z)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a shallow network and test it in MNST data, and run some experiments similar to what shown in [here](http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html) and [here](https://xuwd11.github.io/Dropout_Tutorial_in_PyTorch/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "mnist_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "# Train Set:\n",
    "mnist_train_dataset = torchvision.datasets.MNIST('./data/', train=True, download=True, transform=mnist_transform)\n",
    "mnist_train_loader = DataLoader(mnist_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# Test Set:\n",
    "mnist_test_dataset = torchvision.datasets.MNIST('./data/', train=False, download=True, transform=mnist_transform)\n",
    "mnist_test_loader = DataLoader(mnist_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_data = next(enumerate(mnist_train_loader))\n",
    "sample_data = sample_data[1][0].view(batch_size, 784)[0, :].view(28, 28).data.numpy()\n",
    "plt.imshow(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model (without DropOut) and configure the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlp = MLP(input_size=28*28, nclasses=10, hidden_layers=[800, 800], dropout=0, dropout_input=0)\n",
    "optimizer = torch.optim.SGD(mlp.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "mlp.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "loss_value = 0\n",
    "reset_loss_every = 300\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    for it, train_batch in enumerate(mnist_train_loader):\n",
    "        mlp.train()\n",
    "        \n",
    "        images, train_labels_batch = train_batch\n",
    "        train_data_batch = images.view(train_labels_batch.shape[0], 784)\n",
    "        output = mlp(train_data_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(output, train_labels_batch.to(device), reduction=\"mean\")\n",
    "        \n",
    "        loss.backward()\n",
    "        loss_value += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (it % reset_loss_every) == 0 and it > 0:\n",
    "            print(f\"epoch: {epoch}, iteration: {it}, loss_value: {loss_value/reset_loss_every}\")\n",
    "            loss_value = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlp.eval()\n",
    "gt_test, preds_test = [], []\n",
    "for it_test, test_batch in enumerate(mnist_test_loader):\n",
    "    images, test_labels_batch = test_batch\n",
    "    test_data_batch = images.view(test_labels_batch.shape[0], 784)\n",
    "    output_test = mlp(test_data_batch.to(device).float())\n",
    "    preds_test.append(F.softmax(output_test, dim=1).data.numpy())\n",
    "    gt_test.append(test_labels_batch.numpy())\n",
    "preds_test = np.vstack(preds_test)\n",
    "preds_test_labels = preds_test.argmax(-1)\n",
    "preds_test_score = preds_test.max(-1)\n",
    "gt_test = np.hstack(gt_test)\n",
    "recall, precision = compute_cm(gt_test, preds_test_labels, classes=range(10))\n",
    "print(f'average recall: {recall.mean()},  average precision: {precision.mean()}')\n",
    "preds_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the incorrectly classified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_test_score_threshold = 0.5\n",
    "wrong_samples = np.where(np.logical_and(gt_test != preds_test_labels, preds_test_score > preds_test_score_threshold))[0]\n",
    "wrong_samples_labels = preds_test_labels[wrong_samples]\n",
    "wrong_samples_scores = preds_test_score[wrong_samples]\n",
    "wrong_samples_gt = gt_test[wrong_samples]\n",
    "wrong_samples_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wrong_subset = torch.utils.data.Subset(mnist_test_dataset, wrong_samples)\n",
    "wrong_subset_loader = DataLoader(wrong_subset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And some correct ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_test_score_threshold = 0.5\n",
    "right_samples = np.where(np.logical_and(gt_test == preds_test_labels, preds_test_score > preds_test_score_threshold))[0]\n",
    "right_samples_labels = preds_test_labels[right_samples]\n",
    "right_samples_scores = preds_test_score[right_samples]\n",
    "right_samples_gt = gt_test[right_samples]\n",
    "right_samples_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "right_subset = torch.utils.data.Subset(mnist_test_dataset, right_samples)\n",
    "right_subset_loader = DataLoader(right_subset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-evaluate those images, but with active DropOut "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First re-train the model, with DropOut enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlp_dropout = MLP(input_size=28*28, nclasses=10, hidden_layers=[800, 800], dropout=0.5, dropout_input=0.2)\n",
    "optimizer = torch.optim.SGD(mlp_dropout.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "mlp_dropout.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "loss_value = 0\n",
    "reset_loss_every = 300\n",
    "device = \"cpu\"\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for it, train_batch in enumerate(mnist_train_loader):\n",
    "        mlp_dropout.train()\n",
    "        \n",
    "        images, train_labels_batch = train_batch\n",
    "        train_data_batch = images.view(train_labels_batch.shape[0], 784)\n",
    "        output = mlp_dropout(train_data_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(output, train_labels_batch.to(device), reduction=\"mean\")\n",
    "        \n",
    "        loss.backward()\n",
    "        loss_value += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (it % reset_loss_every) == 0 and it > 0:\n",
    "            print(f\"epoch: {epoch}, iteration: {it}, loss_value: {loss_value/reset_loss_every}\")\n",
    "            loss_value = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the uncertainties for the images with wrong standard Softmax classification results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the uncertainties for the images with incorrect classification results.\n",
    "* Evaluate each image 100 times, while DropOut is switched on.\n",
    "* Pick the label with the largest average softmax probability\n",
    "* Predictive_mean = mean of the label score over the 100 runs\n",
    "* Predictive_std = standard deviation of the label score over the 100 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mlp_dropout.train()\n",
    "\n",
    "ensemble_size = 100\n",
    "\n",
    "number_of_rows = 5\n",
    "idx = 0\n",
    "fig, axes = plt.subplots(number_of_rows, 3, figsize=(16, 20 * number_of_rows // 5))\n",
    "for it, test_batch in enumerate(wrong_subset_loader):\n",
    "    images, target = test_batch\n",
    "    if target.item() not in (3, 5):\n",
    "        continue\n",
    "    scores = []\n",
    "    for _ in range(ensemble_size):\n",
    "        test_data_batch = images.view(target.shape[0], 784)\n",
    "        output_test = mlp_dropout(test_data_batch.to(device).float())\n",
    "        scores.append(F.softmax(output_test, dim=1).data.numpy())\n",
    "    scores = np.vstack(scores)\n",
    "    label = scores.mean(axis=0).argmax(0)\n",
    "    predictive_mean = np.round(np.mean(scores[:, label]), 2)\n",
    "    predictive_std = np.round(np.std(scores[:, label]), 2)\n",
    "    \n",
    "    if wrong_samples_scores[it] > 0.95:\n",
    "        img = images[0, 0].data.numpy()\n",
    "        axes[idx, 0].imshow(img)\n",
    "        axes[idx, 0].set_title(f\"\"\"GroundTruth:{target.item()}, Softmax Prediction:{wrong_samples_labels[it]}, \n",
    "        Softmax Score:{str(np.around(wrong_samples_scores[it], 2))}, BDNN Prediction:{label}\"\"\")\n",
    "        axes[idx, 0].xaxis.set_visible(False)\n",
    "        axes[idx, 0].yaxis.set_visible(False)\n",
    "        axes[idx, 0].xaxis.set_ticks([])\n",
    "        axes[idx, 0].yaxis.set_ticks([])\n",
    "        sb.distplot(scores[:, target.item()], kde=True, kde_kws={'clip': (0.0, 1.0)}, ax=axes[idx, 1])\n",
    "        axes[idx, 1].set_title(f\"Ensemble probabilities of the GT label\")\n",
    "        sb.distplot(scores[:, label], kde=True, kde_kws={'clip': (0.0, 1.0)}, ax=axes[idx, 2])\n",
    "        axes[idx, 2].set_title(f\"Ensemble probabilities of BDNN prediction\")\n",
    "        idx += 1\n",
    "    if idx == number_of_rows:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the uncertainties for the correct results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mlp_dropout.train()\n",
    "\n",
    "ensemble_size = 100\n",
    "\n",
    "number_of_rows = 5\n",
    "idx = 0\n",
    "fig, axes = plt.subplots(number_of_rows, 3, figsize=(16, 20 * number_of_rows // 5))\n",
    "for it, test_batch in enumerate(right_subset_loader):\n",
    "    images, target = test_batch\n",
    "    if target.item() not in (3, 5):\n",
    "        continue\n",
    "    scores = []\n",
    "    for _ in range(ensemble_size):\n",
    "        test_data_batch = images.view(target.shape[0], 784)\n",
    "        output_test = mlp_dropout(test_data_batch.to(device).float())\n",
    "        scores.append(F.softmax(output_test, dim=1).data.numpy())\n",
    "    scores = np.vstack(scores)\n",
    "    label = scores.mean(axis=0).argmax(0)\n",
    "    predictive_mean = np.round(np.mean(scores[:, label]), 2)\n",
    "    predictive_std = np.round(np.std(scores[:, label]), 2)\n",
    "    \n",
    "    if right_samples_scores[it] > 0.95:\n",
    "        img = images[0, 0].data.numpy()\n",
    "        axes[idx, 0].imshow(img)\n",
    "        axes[idx, 0].set_title(f\"\"\"GroundTruth:{target.item()}, Softmax Prediction:{right_samples_labels[it]}, \n",
    "        Softmax Score:{str(np.around(right_samples_scores[it], 2))}, BDNN Prediction:{label}\"\"\")\n",
    "        axes[idx, 0].xaxis.set_visible(False)\n",
    "        axes[idx, 0].yaxis.set_visible(False)\n",
    "        axes[idx, 0].xaxis.set_ticks([])\n",
    "        axes[idx, 0].yaxis.set_ticks([])\n",
    "        sb.distplot(scores[:, target.item()], kde=True, kde_kws={'clip': (0.0, 1.0)}, ax=axes[idx, 1])\n",
    "        axes[idx, 1].set_title(f\"Ensemble probabilities of the GT label\")\n",
    "        sb.distplot(scores[:, label], kde=True, kde_kws={'clip': (0.0, 1.0)}, ax=axes[idx, 2])\n",
    "        axes[idx, 2].set_title(f\"Ensemble probabilities of BDNN prediction\")\n",
    "        idx += 1\n",
    "    if idx == number_of_rows:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the MNIST model on Fashion-MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "fmnist_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.28604105,), (0.35302445,))])\n",
    "fmnist_train_dataset = torchvision.datasets.FashionMNIST('./data/', train=True, download=True, transform=fmnist_transform)\n",
    "fmnist_train_loader = DataLoader(fmnist_train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_data = next(enumerate(fmnist_train_loader))\n",
    "sample_data = sample_data[1][0].view(batch_size, 784)[0, :].view(28, 28).data.numpy()\n",
    "plt.imshow(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mlp_dropout.train()\n",
    "mlp.eval()\n",
    "\n",
    "ensemble_size = 100\n",
    "\n",
    "number_of_rows = 5\n",
    "idx = 0\n",
    "fig, axes = plt.subplots(number_of_rows, 3, figsize=(16, 20 * number_of_rows // 5))\n",
    "for it, test_batch in enumerate(fmnist_train_loader):\n",
    "    images, target = test_batch\n",
    "    \n",
    "    scores = []\n",
    "    for _ in range(ensemble_size):\n",
    "        test_data_batch = images.view(target.shape[0], 784)\n",
    "        output_test = mlp_dropout(test_data_batch.to(device).float())\n",
    "        scores.append(F.softmax(output_test, dim=1).data.numpy())\n",
    "    scores = np.vstack(scores)\n",
    "    label = scores.mean(axis=0).argmax(0)\n",
    "    \n",
    "    test_data_batch = images.view(target.shape[0], 784)\n",
    "    output_test_no_dropout = mlp(test_data_batch.to(device).float())\n",
    "    preds_test_no_dropout = F.softmax(output_test_no_dropout, dim=1).data.numpy()[0]\n",
    "    softmax_label = preds_test_no_dropout.argmax()\n",
    "    softmax_score = preds_test_no_dropout.max()\n",
    "    \n",
    "    if softmax_score > 0.95:\n",
    "        img = images[0, 0].data.numpy()\n",
    "        axes[idx, 0].imshow(img)\n",
    "        axes[idx, 0].set_title(f\"\"\"GroundTruth:{target.item()}, Softmax Prediction:{softmax_label}, \n",
    "        Softmax Score:{str(np.round(softmax_score, 2))}\"\"\")\n",
    "        axes[idx, 0].xaxis.set_visible(False)\n",
    "        axes[idx, 0].yaxis.set_visible(False)\n",
    "        axes[idx, 0].xaxis.set_ticks([])\n",
    "        axes[idx, 0].yaxis.set_ticks([])\n",
    "        sb.distplot(scores[:, target.item()], kde=True, kde_kws={'clip': (0.0, 1.0)}, ax=axes[idx, 1])\n",
    "        axes[idx, 1].set_title(f\"Ensemble probabilities of the GT label: {target.item()}\")\n",
    "        sb.distplot(scores[:, label], kde=True, kde_kws={'clip': (0.0, 1.0)}, ax=axes[idx, 2])\n",
    "        axes[idx, 2].set_title(f\"Ensemble probabilities of BDNN prediction: {label}\")\n",
    "        idx += 1\n",
    "    if idx == number_of_rows:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
