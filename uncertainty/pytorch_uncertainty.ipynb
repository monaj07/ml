{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "#----------------------\n",
    "from dataset import CreateDataBatches\n",
    "from models import Model\n",
    "from utils_cm import compute_cm, split_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate synthetic data using Gaussians\n",
    "sizes = [1000, 1000]\n",
    "\n",
    "# class0:\n",
    "mu0 = np.array([-1, 7])\n",
    "cov0 = np.array([[1, 0], [0, 1]]) * 0.15\n",
    "data0 = np.random.multivariate_normal(mu0, cov0, size=sizes[0])\n",
    "\n",
    "# class1:\n",
    "mu1 = np.array([5, -3])\n",
    "cov1 = np.array([[10, 0], [0, 10]]) * 0.5\n",
    "data1 = np.random.multivariate_normal(mu1, cov1, size=sizes[1])\n",
    "\n",
    "### Combine data from different classes, shuffle them and split it into train, validation and test sets\n",
    "data = np.vstack([data0, data1])\n",
    "labels = np.concatenate([i * np.ones(sizes[i]) for i in range(len(sizes))]).astype(int)\n",
    "N = sum(sizes)\n",
    "split = [0.6, 0.8, 1]\n",
    "data_train, labels_train, data_val, labels_val, data_test, labels_test = split_dataset(data, labels, split)\n",
    "data_mean = data_train.mean(axis=0)\n",
    "data_std = data_train.std(axis=0)\n",
    "\n",
    "classes = np.unique(labels)\n",
    "class_colours = ['r', 'b']\n",
    "\n",
    "idx_train = [np.where(labels_train == c)[0] for c in classes]\n",
    "idx_test = [np.where(labels_test == c)[0] for c in classes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in classes:\n",
    "    plt.scatter(data_train[idx_train[c], 0], data_train[idx_train[c], 1], marker='.', s=100, color=class_colours[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = True\n",
    "trainloader = DataLoader(CreateDataBatches(data_train, labels_train, data_mean, data_std, normalize=normalize), batch_size=16, shuffle=True)\n",
    "valloader = DataLoader(CreateDataBatches(data_val, labels_val, data_mean, data_std, normalize=normalize), batch_size=16, shuffle=False)\n",
    "testloader = DataLoader(CreateDataBatches(data_test, labels_test, data_mean, data_std, normalize=normalize), batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_size=data_train.shape[-1], nclasses=len(classes), hidden_layers=[8], dropout=0.5)\n",
    "model.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_value = 0\n",
    "n_epochs = 1\n",
    "reset_loss_every = 10\n",
    "\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    for it, train_batch in enumerate(trainloader):\n",
    "        model.train()\n",
    "        train_data_batch, train_labels_batch = train_batch\n",
    "        output = model(train_data_batch.to(device).float())\n",
    "        optim.zero_grad()\n",
    "        loss = F.cross_entropy(output, train_labels_batch.to(device), reduction=\"mean\")\n",
    "        loss.backward()\n",
    "        loss_value += loss.data.item()\n",
    "        optim.step()\n",
    "\n",
    "        if it % reset_loss_every == 0 and it > 0:\n",
    "            model.eval()\n",
    "            gt_val, preds_val = [], []\n",
    "            for it_val, val_batch in enumerate(valloader):\n",
    "                val_data_batch, val_labels_batch = val_batch\n",
    "                output_val = model(val_data_batch.to(device).float())\n",
    "                preds_val.append(F.softmax(output_val, dim=1).data.numpy().argmax(axis=1))\n",
    "                gt_val.append(val_labels_batch.numpy())\n",
    "            preds_val = np.hstack(preds_val)\n",
    "            gt_val = np.hstack(gt_val)\n",
    "            recall, precision = compute_cm(gt_val, preds_val, classes)\n",
    "            average_loss = np.round(loss_value / reset_loss_every, 4)\n",
    "            print(f'epoch: {epoch}, iteration: {it}, recall: {recall},  precision: {precision}, average_loss: {average_loss}')\n",
    "            loss_value = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify all grid points to visualize decision boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis0_min = data_test[:, 0].min()\n",
    "axis0_max = data_test[:, 0].max()\n",
    "axis1_min = data_test[:, 1].min()\n",
    "axis1_max = data_test[:, 1].max()\n",
    "range_0 = np.arange(axis0_min, axis0_max, .1)\n",
    "range_1 = np.arange(axis1_min, axis1_max, .1)\n",
    "data_grid = np.array([(x0, x1) for x0 in range_0\n",
    "                               for x1 in range_1])\n",
    "gridloader = DataLoader(CreateDataBatches\n",
    "                        (data_grid, 0*data_grid[:, 0], data_mean, data_std, normalize=normalize), \n",
    "                         batch_size=16, shuffle=False)\n",
    "# stats.describe(data_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "preds_grid = []\n",
    "for it_grid, grid_batch in enumerate(gridloader):\n",
    "    grid_data_batch, _ = grid_batch\n",
    "    output_grid = model(grid_data_batch.to(device).float())\n",
    "    preds_grid.append(F.softmax(output_grid, dim=1).data.numpy())\n",
    "preds_grid = np.vstack(preds_grid)\n",
    "preds_grid_score = preds_grid.max(-1)\n",
    "# preds_grid_score = preds_grid[:, 1]\n",
    "preds_grid_labels = preds_grid.argmax(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "gt_test, preds_test = [], []\n",
    "for it_test, test_batch in enumerate(testloader):\n",
    "    test_data_batch, test_labels_batch = test_batch\n",
    "    output_test = model(test_data_batch.to(device).float())\n",
    "    preds_test.append(F.softmax(output_test, dim=1).data.numpy())\n",
    "    gt_test.append(test_labels_batch.numpy())\n",
    "preds_test = np.vstack(preds_test)\n",
    "preds_test_labels = preds_test.argmax(-1)\n",
    "preds_test_score = preds_test.max(-1)\n",
    "gt_test = np.hstack(gt_test)\n",
    "recall, precision = compute_cm(gt_test, preds_test_labels, classes)\n",
    "print(f'recall: {recall},  precision: {precision}')\n",
    "preds_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(18, 16))\n",
    "\n",
    "score_grid = preds_grid_score.reshape((len(range_0), len(range_1)))\n",
    "plt.imshow(score_grid.T, origin='lower', aspect='auto', extent=(axis0_min, axis0_max, axis1_min, axis1_max))\n",
    "plt.colorbar()\n",
    "\n",
    "# for c in classes:\n",
    "#     plt.scatter(data_grid[preds_grid_labels==c, 0], data_grid[preds_grid_labels==c, 1], \n",
    "#                 marker='.', s=100, color=class_colours[c], alpha = 0.05)\n",
    "\n",
    "markers = ['s', 'o']\n",
    "for c in classes:\n",
    "    plt.scatter(data_test[gt_test==c, 0], data_test[gt_test==c, 1], \n",
    "                marker=markers[c], edgecolors='k', s=100, color=class_colours[c])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
