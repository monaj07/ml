{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_sloth = Image.open(\"sloth.jpg\")\n",
    "image_sloth = image_sloth.resize((224, 224))\n",
    "plt.imshow(image_sloth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Image to a Pytorch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_tensor = transforms.Compose([transforms.ToTensor()])\n",
    "transform_norm = transforms.Compose([transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "image_tensor = transform_norm(transform_tensor(image_sloth)).float().unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify the image using a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "model.eval()\n",
    "true_prediction = model(image_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Prediction Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_labels = dict(pd.read_csv('../mobilenet-feat/imagenet_labels.csv').values)\n",
    "print(imagenet_labels[true_prediction.max(dim=1)[1].item()])\n",
    "true_confidence, true_pred_label = F.softmax(true_prediction, dim=1).max(dim=1)\n",
    "print(f\"Prediction confidence = {true_confidence.data.numpy()}\")\n",
    "print(f\"Class label in ImageNet = {true_pred_label.data.numpy()}\")\n",
    "print(f\"Loss = {F.cross_entropy(true_prediction, true_pred_label).item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an adversarial example\n",
    "This can be done by carefully modifying the image such that the change is un-noticeable to the human eye, but confuses the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = torch.zeros_like(transform_tensor(image_sloth), requires_grad=True)\n",
    "optimizer = torch.optim.SGD([delta], lr=.9)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "model.to(device)\n",
    "print(device)\n",
    "epsilon = 1./255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in range(51):\n",
    "    image_tensor = transform_norm(transform_tensor(image_sloth) + delta).float().unsqueeze(0)\n",
    "    prediction = model(image_tensor.to(device))\n",
    "    loss = -F.cross_entropy(prediction, true_pred_label)\n",
    "    if it % 10 == 0:\n",
    "        print(f\"iteration {it}, loss = {loss.item()}\")\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    delta.data.clamp_(-epsilon, epsilon)\n",
    "    \n",
    "print(\"True class probability:\", F.softmax(prediction, dim=1)[0, true_pred_label].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given the optimized noise, the class with the highest prediction score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_class = prediction.max(dim=1)[1].item()\n",
    "print(imagenet_labels[prediction.max(dim=1)[1].item()])\n",
    "confidence, pred_label = F.softmax(prediction, dim=1).max(dim=1)\n",
    "print(f\"Prediction confidence = {confidence.data.numpy()}\")\n",
    "print(f\"Class label in ImageNet = {pred_label.data.numpy()}\")\n",
    "print(f\"Loss = {F.cross_entropy(prediction, pred_label).item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The updated image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image_sloth = transform_tensor(image_sloth) + delta\n",
    "new_image_sloth = new_image_sloth.squeeze().data.numpy().transpose(1,2,0)\n",
    "new_image_sloth = np.clip(new_image_sloth, 0, 1)\n",
    "noise = delta.squeeze().data.numpy().transpose(1,2,0)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].imshow(image_sloth), ax[0].set_title(imagenet_labels[true_prediction.max(dim=1)[1].item()][:20]+\"...\")\n",
    "ax[1].imshow(new_image_sloth), ax[1].set_title(imagenet_labels[prediction.max(dim=1)[1].item()][:20]+\"...\")\n",
    "ax[2].imshow(noise * 200), ax[2].set_title(\"Added niose x 200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Max pixel value in the raw image: {np.array(image_sloth).max()}\")\n",
    "print(f\"Max pixel value in the noise image: {np.abs(noise).max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's turn our SLOTH into a KOALA!\n",
    "The index of the koala in ImageNet class-list is 105."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_label = torch.LongTensor([388])\n",
    "delta = torch.zeros_like(transform_tensor(image_sloth), requires_grad=True)\n",
    "optimizer = torch.optim.SGD([delta], lr=.009)\n",
    "\n",
    "for it in range(51):\n",
    "    image_tensor = transform_norm(transform_tensor(image_sloth) + delta).float().unsqueeze(0)\n",
    "    prediction = model(image_tensor.to(device))\n",
    "    loss = -F.cross_entropy(prediction, true_pred_label) + F.cross_entropy(prediction, fake_label)\n",
    "    if it % 10 == 0:\n",
    "        print(f\"iteration {it}, loss = {loss.item()}\")\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    delta.data.clamp_(-epsilon, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_class = prediction.max(dim=1)[1].item()\n",
    "print(imagenet_labels[prediction.max(dim=1)[1].item()])\n",
    "confidence, pred_label = F.softmax(prediction, dim=1).max(dim=1)\n",
    "print(f\"Prediction confidence = {confidence.data.numpy()}\")\n",
    "print(f\"Class label in ImageNet = {pred_label.data.numpy()}\")\n",
    "print(f\"Loss = {F.cross_entropy(prediction, pred_label).item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the attacked image with the raw image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image_sloth = transform_tensor(image_sloth) + delta\n",
    "new_image_sloth = new_image_sloth.squeeze().data.numpy().transpose(1,2,0)\n",
    "new_image_sloth = np.clip(new_image_sloth, 0, 1)\n",
    "noise = delta.squeeze().data.numpy().transpose(1,2,0)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].imshow(image_sloth), ax[0].set_title(imagenet_labels[true_prediction.max(dim=1)[1].item()][:20]+\"...\")\n",
    "ax[1].imshow(new_image_sloth), ax[1].set_title(imagenet_labels[prediction.max(dim=1)[1].item()][:20]+\"...\")\n",
    "ax[2].imshow(noise * 200), ax[2].set_title(\"Added niose x 200\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### References: \n",
    "https://adversarial-ml-tutorial.org/\n",
    "\n",
    "https://openai.com/blog/adversarial-example-research/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
