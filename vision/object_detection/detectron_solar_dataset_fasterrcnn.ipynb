{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a81d928a",
   "metadata": {},
   "source": [
    "# Solar Panel Detection using Faster RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98ab1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyyaml==5.1\n",
    "# !pip install torch==1.9.0+cu102 torchvision==0.10.0+cu102 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "# Install detectron2 that matches the above pytorch version\n",
    "# !pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.9/index.html\n",
    "# exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55644eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check pytorch installation: \n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "# assert torch.__version__.startswith(\"1.9\")   # please manually install torch 1.9 if Colab changes its default version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56477b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption: matplotlib, numpy, opencv are installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea22745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777ca8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1364)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14e37e2",
   "metadata": {},
   "source": [
    "# Train on custom datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3c7857",
   "metadata": {},
   "source": [
    "### Download the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7b876e",
   "metadata": {},
   "source": [
    "The solar_array dataset for 4 different cities can be found in the following link/article:\n",
    "https://www.nature.com/articles/sdata2016106#ref-CR40\n",
    "\n",
    "Four different aerial datasets:\n",
    "https://figshare.com/articles/dataset/Fresno_Aerial_USGS_Imagery_from_the_Distributed_Solar_Photovoltaic_Array_Location_and_Extent_Data_Set/3385828 (**Fresno**, [28.7GB](https://ndownloader.figshare.com/articles/3385828/versions/1))\n",
    "https://figshare.com/articles/dataset/Stockton_Aerial_USGS_Imagery_from_the_Distributed_Solar_Photovoltaic_Array_Location_and_Extent_Data_Set/3385804 (**Stockton**, [6.5GB](https://ndownloader.figshare.com/articles/3385804/versions/1))\n",
    "https://figshare.com/articles/dataset/Oxnard_Aerial_USGS_Imagery_from_the_Distributed_Solar_Photovoltaic_Array_Location_and_Extent_Data_Set/3385807 (**Oxnard**, [5GB](https://ndownloader.figshare.com/articles/3385807/versions/1))\n",
    "https://figshare.com/articles/dataset/Modesto_Aerial_USGS_Imagery_from_the_Distributed_Solar_Photovoltaic_Array_Location_and_Extent_Data_Set/3385789 (**Modesto**, [1.4GB](https://ndownloader.figshare.com/articles/3385789/versions/1))\n",
    "\n",
    "In this notebook, we use the **Fresno** dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed7861f",
   "metadata": {},
   "source": [
    "The mask annotations (polygons) for all four datasets are provided by the article:\n",
    "\n",
    "[Data Descriptor: Distributed solar photovoltaic array location and extent dataset for remote sensing object identification](https://www.nature.com/articles/sdata2016106.pdf)\n",
    "\n",
    "and can be downloaded from this link:\n",
    "https://figshare.com/articles/dataset/Distributed_Solar_Photovoltaic_Array_Location_and_Extent_Data_Set_for_Remote_Sensing_Object_Identification/3385780?backTo=/collections/Full_Collection_Distributed_Solar_Photovoltaic_Array_Location_and_Extent_Data_Set_for_Remote_Sensing_Object_Identification/3255643\n",
    "\n",
    "It contains annotation data in various forms and formats (lat-long coordinates, pixelwise coordinates, csv, json, ...).\n",
    "\n",
    "In fact we only require the polygon-json dataset (<u>*SolarArrayPolygons.json*</u>) which can be individually downloaded from:\n",
    "\n",
    "https://ndownloader.figshare.com/files/24115694"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7156cae9",
   "metadata": {},
   "source": [
    "#### Or you can just download the required images and annotation files from these two links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2571eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://ndownloader.figshare.com/articles/3385804/versions/1\n",
    "# !wget https://ndownloader.figshare.com/articles/3385780/versions/4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6facf919",
   "metadata": {},
   "source": [
    "#### Unzip the downloaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6362b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip 1 -d solar_array_dataset\n",
    "# !unzip 4 -d solar_array_dataset_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c1125d",
   "metadata": {},
   "source": [
    "#### An example ground truth bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26373342",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('solar_array_dataset/10sfg465970.tif')\n",
    "img = np.array(img)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8bd7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[4050:4075, 4055:4085, :])  # An example bounding box taken from the annorations for this image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db06df7",
   "metadata": {},
   "source": [
    "#### Get the list of image filenames for different splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2290d07",
   "metadata": {},
   "source": [
    "(train, val, test): (70, 15, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db044184",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(\"solar_array_dataset/*.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa529756",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = len(filenames)\n",
    "train_size = int(0.7 * total_size)\n",
    "val_size = int(0.15 * total_size)\n",
    "test_size = total_size - train_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcab36f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(filenames) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c54486",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_split = {}\n",
    "filenames_split['train'] = filenames[:train_size]\n",
    "filenames_split['val'] = filenames[train_size: (train_size + val_size)]\n",
    "filenames_split['test'] = filenames[-test_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fb303a",
   "metadata": {},
   "source": [
    "### Register train/val/test datasets (converting arbitrary dataset formats to COCO format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dd72d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if your dataset is in COCO format, this cell can be replaced by the following three lines:\n",
    "# from detectron2.data.datasets import register_coco_instances\n",
    "# register_coco_instances(\"my_dataset_train\", {}, \"json_annotation_train.json\", \"path/to/image/dir\")\n",
    "# register_coco_instances(\"my_dataset_val\", {}, \"json_annotation_val.json\", \"path/to/image/dir\")\n",
    "\n",
    "from detectron2.structures import BoxMode\n",
    "\n",
    "def get_solar_dicts(split):\n",
    "    with open(os.path.join(\"solar_array_dataset_annotations\", \"SolarArrayPolygons.json\")) as f:\n",
    "        imgs_anns = json.load(f)\n",
    "\n",
    "    dataset_dicts = []\n",
    "    \n",
    "    for filename in tqdm.tqdm(filenames_split[split], total=len(filenames_split[split]), desc=f'{split}_data loading'):\n",
    "        record = {}\n",
    "        \n",
    "        img = Image.open(filename)\n",
    "        img = np.array(img)\n",
    "        height, width = img.shape[:2]\n",
    "        \n",
    "        record[\"file_name\"] = filename\n",
    "        record[\"image_id\"] = 0\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "        \n",
    "        filename_id = os.path.splitext(os.path.basename(filename))[0]\n",
    "        \n",
    "        relevant_items = [item for item in imgs_anns['polygons'] if item['image_name'] == filename_id]\n",
    "      \n",
    "        objs = []\n",
    "        for item in relevant_items:\n",
    "            vertices = item[\"polygon_vertices_pixels\"]\n",
    "            px = [vertex[0] for vertex in vertices]\n",
    "            py = [vertex[1] for vertex in vertices]\n",
    "            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
    "            poly = [p for x in poly for p in x]\n",
    "\n",
    "            obj = {\n",
    "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                \"segmentation\": [poly],\n",
    "                \"category_id\": 0,  # only one single object class (solar)\n",
    "            }\n",
    "            objs.append(obj)\n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "    return dataset_dicts\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    DatasetCatalog.register(\"solar_\" + split, lambda split=split: get_solar_dicts(split))\n",
    "    MetadataCatalog.get(\"solar_\" + split).set(thing_classes=[\"solar\"])\n",
    "solar_train_metadata = MetadataCatalog.get(\"solar_train\")\n",
    "solar_val_metadata = MetadataCatalog.get(\"solar_val\")\n",
    "solar_test_metadata = MetadataCatalog.get(\"solar_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b8a330",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dicts = get_solar_dicts('train')\n",
    "solar_metadata = solar_train_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc7b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in random.sample(dataset_dicts, 3):\n",
    "    img = Image.open(d['file_name'])\n",
    "    img = np.array(img)\n",
    "    visualizer = Visualizer(img, metadata=solar_metadata, scale=1)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    print(out.get_image().shape)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(20, 20))\n",
    "    imgPIL = Image.fromarray(out.get_image())\n",
    "    imgPIL.save(f\"sample_gt_{os.path.splitext(os.path.basename(d['file_name']))[0]}.tif\")\n",
    "    ax.imshow(out.get_image())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1140c2",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a2fb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
    "\n",
    "class CocoTrainer(DefaultTrainer):\n",
    "\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs(\"eval_dir\", exist_ok=True)\n",
    "            output_folder = \"eval_dir\"\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a300d09",
   "metadata": {},
   "source": [
    "#### Instantiate a Faster-RCNN config object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6cec75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"solar_train\",)\n",
    "cfg.DATASETS.VAL = (\"solar_val\",)\n",
    "cfg.DATASETS.TEST = (\"solar_test\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")  \n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 20001    \n",
    "cfg.TEST.EVAL_PERIOD = 1000\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (solar). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d4c6cd",
   "metadata": {},
   "source": [
    "#### Actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd47a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = CocoTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a9ea37",
   "metadata": {},
   "source": [
    "## Inference/Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4c3315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e122da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the COCO Evaluator to use the COCO Metrics\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "# Call the COCO Evaluator function and pass the Validation Dataset\n",
    "evaluator = COCOEvaluator(\"solar_val\", cfg, False, output_dir=\"output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"solar_val\")\n",
    "\n",
    "# Use the created predicted model in the previous step\n",
    "inference_on_dataset(predictor.model, val_loader, evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7916dd",
   "metadata": {},
   "source": [
    "#### Sample Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac6a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dicts = get_solar_dicts('train')\n",
    "solar_metadata = solar_train_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae502c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "for d in random.sample(dataset_dicts, 3):\n",
    "    img = Image.open(d[\"file_name\"])\n",
    "    img = np.array(img)\n",
    "    outputs = predictor(img)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "    print(outputs[\"instances\"])\n",
    "    v = Visualizer(img,\n",
    "                   metadata=solar_metadata, \n",
    "                   scale=1, \n",
    "                   instance_mode=ColorMode.IMAGE \n",
    "    )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    imgPIL = Image.fromarray(out.get_image())\n",
    "    imgPIL.save(f\"sample_pred_fasterrcnn_{os.path.splitext(os.path.basename(d['file_name']))[0]}.tif\")\n",
    "    plt.imshow(out.get_image())\n",
    "    plt.show()\n",
    "    # print(outputs[\"instances\"].to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098348a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "old_detectron",
   "language": "python",
   "name": "old_detectron"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
